{
  "message": "ValueError: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Sequential name=sequential, built=False> (of type <class 'keras.src.models.sequential.Sequential'>)\n\u001b[90mRun \u001b]8;;rstudio:run:reticulate::py_last_error()\u0007`reticulate::py_last_error()`\u001b]8;;\u0007 for details.\u001b[39m",
  "traceback": ["py_call_impl(callable, call_args$unnamed, call_args$named)", "layer(object, ...)", "compose_layer.default(object, layer)", "compose_layer(object, layer)", "create_layer(keras$layers$Dropout, object, list(rate = rate, \n    noise_shape = normalize_shape(noise_shape), seed = seed, \n    input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n    batch_size = as_nullable_integer(batch_size), name = name, \n    trainable = trainable, weights = weights))", "layer_dropout(., rate = FLAGS$dropout1)", "create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n    activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n    bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n    bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n    kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n    input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n    batch_size = as_nullable_integer(batch_size), dtype = dtype, \n    name = name, trainable = trainable, weights = weights))", "layer_dense(., units = FLAGS$units2, activation = \"relu\")", "create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n    activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n    bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n    bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n    kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n    input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n    batch_size = as_nullable_integer(batch_size), dtype = dtype, \n    name = name, trainable = trainable, weights = weights))", "layer_dense(., units = 1)", "model %>% layer_dropout(rate = FLAGS$dropout1) %>% layer_dense(units = FLAGS$units2, \n    activation = \"relu\") %>% layer_dense(units = 1)", "eval(ei, envir)", "eval(ei, envir)", "withVisible(eval(ei, envir))", "tuning_run(\"train_model.R\", flags = list(units1 = c(32, 64, 128), \n    units2 = c(16, 32, 64), dropout1 = c(0.2, 0.3, 0.4), lr = c(0.001, \n        5e-04), batch_size = c(128, 256)))"]
}
